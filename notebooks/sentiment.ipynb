{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zaCxxZG6NUl_",
    "outputId": "0acce7bc-2f13-4c2a-fbf6-9d5ba255b37a"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Package                 Version\n",
      "----------------------- ----------\n",
      "absl-py                 1.3.0\n",
      "aiohttp                 3.8.3\n",
      "aiosignal               1.2.0\n",
      "anyio                   3.5.0\n",
      "appdirs                 1.4.4\n",
      "appnope                 0.1.2\n",
      "argon2-cffi             21.3.0\n",
      "argon2-cffi-bindings    21.2.0\n",
      "astor                   0.8.1\n",
      "asttokens               2.0.5\n",
      "astunparse              1.6.3\n",
      "async-timeout           4.0.2\n",
      "attrs                   22.1.0\n",
      "Babel                   2.11.0\n",
      "backcall                0.2.0\n",
      "beautifulsoup4          4.12.2\n",
      "bleach                  4.1.0\n",
      "blinker                 1.4\n",
      "boltons                 23.0.0\n",
      "Bottleneck              1.3.5\n",
      "brotlipy                0.7.0\n",
      "cachetools              4.2.2\n",
      "certifi                 2023.5.7\n",
      "cffi                    1.15.1\n",
      "charset-normalizer      2.0.4\n",
      "click                   8.0.4\n",
      "comm                    0.1.2\n",
      "conda                   23.3.1\n",
      "conda-content-trust     0.1.3\n",
      "conda-package-handling  2.0.2\n",
      "conda_package_streaming 0.7.0\n",
      "contourpy               1.0.5\n",
      "cryptography            39.0.1\n",
      "cycler                  0.11.0\n",
      "debugpy                 1.5.1\n",
      "decorator               5.1.1\n",
      "defusedxml              0.7.1\n",
      "entrypoints             0.4\n",
      "executing               0.8.3\n",
      "fastjsonschema          2.16.2\n",
      "filelock                3.12.0\n",
      "flatbuffers             2.0\n",
      "fonttools               4.25.0\n",
      "frozenlist              1.3.3\n",
      "fsspec                  2023.5.0\n",
      "gast                    0.4.0\n",
      "google-auth             2.6.0\n",
      "google-auth-oauthlib    0.4.4\n",
      "google-pasta            0.2.0\n",
      "grpcio                  1.42.0\n",
      "h5py                    3.7.0\n",
      "huggingface-hub         0.14.1\n",
      "idna                    3.4\n",
      "imageio                 2.28.1\n",
      "importlib-metadata      6.0.0\n",
      "importlib-resources     5.2.0\n",
      "ipykernel               6.19.2\n",
      "ipython                 8.12.0\n",
      "ipython-genutils        0.2.0\n",
      "ipywidgets              8.0.4\n",
      "jedi                    0.18.1\n",
      "Jinja2                  3.1.2\n",
      "json5                   0.9.6\n",
      "jsonpatch               1.32\n",
      "jsonpointer             2.1\n",
      "jsonschema              4.17.3\n",
      "jupyter                 1.0.0\n",
      "jupyter_client          8.1.0\n",
      "jupyter-console         6.6.3\n",
      "jupyter_core            5.3.0\n",
      "jupyter-server          1.23.4\n",
      "jupyterlab              3.5.3\n",
      "jupyterlab-pygments     0.1.2\n",
      "jupyterlab_server       2.22.0\n",
      "jupyterlab-widgets      3.0.5\n",
      "keras                   2.10.0\n",
      "Keras-Preprocessing     1.1.2\n",
      "kiwisolver              1.4.4\n",
      "lxml                    4.9.2\n",
      "Markdown                3.4.1\n",
      "MarkupSafe              2.1.1\n",
      "matplotlib              3.7.1\n",
      "matplotlib-inline       0.1.6\n",
      "mistune                 0.8.4\n",
      "mkl-fft                 1.3.6\n",
      "mkl-random              1.2.2\n",
      "mkl-service             2.4.0\n",
      "multidict               6.0.2\n",
      "munkres                 1.1.4\n",
      "nbclassic               0.5.5\n",
      "nbclient                0.5.13\n",
      "nbconvert               6.5.4\n",
      "nbformat                5.7.0\n",
      "nest-asyncio            1.5.6\n",
      "notebook                6.5.4\n",
      "notebook_shim           0.2.2\n",
      "numexpr                 2.8.4\n",
      "numpy                   1.24.3\n",
      "oauthlib                3.2.2\n",
      "opencv-python           4.7.0.72\n",
      "opt-einsum              3.3.0\n",
      "packaging               23.0\n",
      "pandas                  1.5.3\n",
      "pandocfilters           1.5.0\n",
      "parso                   0.8.3\n",
      "pexpect                 4.8.0\n",
      "pickleshare             0.7.5\n",
      "Pillow                  9.4.0\n",
      "pip                     23.0.1\n",
      "platformdirs            2.5.2\n",
      "pluggy                  1.0.0\n",
      "ply                     3.11\n",
      "pooch                   1.4.0\n",
      "prometheus-client       0.14.1\n",
      "prompt-toolkit          3.0.36\n",
      "protobuf                3.20.3\n",
      "psutil                  5.9.0\n",
      "ptyprocess              0.7.0\n",
      "pure-eval               0.2.2\n",
      "pyasn1                  0.4.8\n",
      "pyasn1-modules          0.2.8\n",
      "pycosat                 0.6.4\n",
      "pycparser               2.21\n",
      "Pygments                2.15.1\n",
      "PyJWT                   2.4.0\n",
      "pyOpenSSL               23.0.0\n",
      "pyparsing               3.0.9\n",
      "PyQt5-sip               12.11.0\n",
      "pyrsistent              0.18.0\n",
      "PySocks                 1.7.1\n",
      "python-dateutil         2.8.2\n",
      "pytz                    2022.7\n",
      "PyYAML                  6.0\n",
      "pyzmq                   25.0.2\n",
      "qtconsole               5.4.2\n",
      "QtPy                    2.2.0\n",
      "regex                   2023.5.5\n",
      "requests                2.28.1\n",
      "requests-oauthlib       1.3.0\n",
      "rsa                     4.7.2\n",
      "ruamel.yaml             0.17.21\n",
      "ruamel.yaml.clib        0.2.6\n",
      "scipy                   1.10.1\n",
      "Send2Trash              1.8.0\n",
      "setuptools              65.6.3\n",
      "sip                     6.6.2\n",
      "six                     1.16.0\n",
      "sniffio                 1.2.0\n",
      "soupsieve               2.4\n",
      "stack-data              0.2.0\n",
      "tensorboard             2.10.0\n",
      "tensorboard-data-server 0.6.1\n",
      "tensorboard-plugin-wit  1.6.0\n",
      "tensorflow              2.10.0\n",
      "tensorflow-docs         0.0.0.dev0\n",
      "tensorflow-estimator    2.10.0\n",
      "tensorflow-hub          0.13.0\n",
      "termcolor               2.1.0\n",
      "terminado               0.17.1\n",
      "tinycss2                1.2.1\n",
      "tokenizers              0.13.3\n",
      "toml                    0.10.2\n",
      "tomli                   2.0.1\n",
      "toolz                   0.12.0\n",
      "tornado                 6.2\n",
      "tqdm                    4.65.0\n",
      "traitlets               5.7.1\n",
      "transformers            4.29.2\n",
      "typing_extensions       4.5.0\n",
      "urllib3                 1.26.15\n",
      "wcwidth                 0.2.5\n",
      "webencodings            0.5.1\n",
      "websocket-client        0.58.0\n",
      "Werkzeug                2.2.3\n",
      "wheel                   0.35.1\n",
      "widgetsnbextension      4.0.5\n",
      "wrapt                   1.14.1\n",
      "yarl                    1.8.1\n",
      "zipp                    3.11.0\n",
      "zstandard               0.19.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-05-18 14:01:33.806805: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE4.1 SSE4.2\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "LoRBSx3oNHrL"
   },
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "from transformers import TFAutoModelForSequenceClassification\n",
    "from transformers import AutoTokenizer\n",
    "import numpy as np\n",
    "from scipy.special import softmax\n",
    "import csv\n",
    "import urllib.request"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PGwwBb3UNMax",
    "outputId": "2af0acba-759c-4581-aca1-c83b9643061a"
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "\nAutoModelForSequenceClassification requires the PyTorch library but it was not found in your environment.\nHowever, we were able to find a TensorFlow installation. TensorFlow classes begin\nwith \"TF\", but are otherwise identically named to our PyTorch classes. This\nmeans that the TF equivalent of the class you tried to import would be \"TFAutoModelForSequenceClassification\".\nIf you want to use TensorFlow, please use TF classes instead!\n\nIf you really do want to use PyTorch please go to\nhttps://pytorch.org/get-started/locally/ and follow the instructions that\nmatch your environment.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 30\u001b[0m\n\u001b[1;32m     27\u001b[0m labels \u001b[38;5;241m=\u001b[39m [row[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m row \u001b[38;5;129;01min\u001b[39;00m csvreader \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(row) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# PT\u001b[39;00m\n\u001b[0;32m---> 30\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mAutoModelForSequenceClassification\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_pretrained\u001b[49m(MODEL)\n\u001b[1;32m     31\u001b[0m model\u001b[38;5;241m.\u001b[39msave_pretrained(MODEL)\n\u001b[1;32m     33\u001b[0m text \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mGood night 😊\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/transformers/utils/import_utils.py:1112\u001b[0m, in \u001b[0;36mDummyObject.__getattribute__\u001b[0;34m(cls, key)\u001b[0m\n\u001b[1;32m   1110\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m key\u001b[38;5;241m.\u001b[39mstartswith(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m key \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m_from_config\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   1111\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__getattribute__\u001b[39m(key)\n\u001b[0;32m-> 1112\u001b[0m \u001b[43mrequires_backends\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backends\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/lib/python3.9/site-packages/transformers/utils/import_utils.py:1091\u001b[0m, in \u001b[0;36mrequires_backends\u001b[0;34m(obj, backends)\u001b[0m\n\u001b[1;32m   1089\u001b[0m \u001b[38;5;66;03m# Raise an error for users who might not realize that classes without \"TF\" are torch-only\u001b[39;00m\n\u001b[1;32m   1090\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorch\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m backends \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m backends \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_torch_available() \u001b[38;5;129;01mand\u001b[39;00m is_tf_available():\n\u001b[0;32m-> 1091\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(PYTORCH_IMPORT_ERROR_WITH_TF\u001b[38;5;241m.\u001b[39mformat(name))\n\u001b[1;32m   1093\u001b[0m \u001b[38;5;66;03m# Raise the inverse error for PyTorch users trying to load TF classes\u001b[39;00m\n\u001b[1;32m   1094\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtf\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m backends \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtorch\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m backends \u001b[38;5;129;01mand\u001b[39;00m is_torch_available() \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_tf_available():\n",
      "\u001b[0;31mImportError\u001b[0m: \nAutoModelForSequenceClassification requires the PyTorch library but it was not found in your environment.\nHowever, we were able to find a TensorFlow installation. TensorFlow classes begin\nwith \"TF\", but are otherwise identically named to our PyTorch classes. This\nmeans that the TF equivalent of the class you tried to import would be \"TFAutoModelForSequenceClassification\".\nIf you want to use TensorFlow, please use TF classes instead!\n\nIf you really do want to use PyTorch please go to\nhttps://pytorch.org/get-started/locally/ and follow the instructions that\nmatch your environment.\n"
     ]
    }
   ],
   "source": [
    "# Preprocess text (username and link placeholders)\n",
    "def preprocess(text):\n",
    "    new_text = []\n",
    " \n",
    " \n",
    "    for t in text.split(\" \"):\n",
    "        t = '@user' if t.startswith('@') and len(t) > 1 else t\n",
    "        t = 'http' if t.startswith('http') else t\n",
    "        new_text.append(t)\n",
    "    return \" \".join(new_text)\n",
    "\n",
    "# Tasks:\n",
    "# emoji, emotion, hate, irony, offensive, sentiment\n",
    "# stance/abortion, stance/atheism, stance/climate, stance/feminist, stance/hillary\n",
    "\n",
    "task='sentiment'\n",
    "MODEL = f\"cardiffnlp/twitter-roberta-base-{task}\"\n",
    "\n",
    "# tokenizer = AutoTokenizer.from_pretrained(MODEL)\n",
    "\n",
    "# download label mapping\n",
    "labels=[]\n",
    "mapping_link = f\"https://raw.githubusercontent.com/cardiffnlp/tweeteval/main/datasets/{task}/mapping.txt\"\n",
    "with urllib.request.urlopen(mapping_link) as f:\n",
    "    html = f.read().decode('utf-8').split(\"\\n\")\n",
    "    csvreader = csv.reader(html, delimiter='\\t')\n",
    "labels = [row[1] for row in csvreader if len(row) > 1]\n",
    "\n",
    "# PT\n",
    "model = AutoModelForSequenceClassification.from_pretrained(MODEL)\n",
    "model.save_pretrained(MODEL)\n",
    "\n",
    "text = \"Good night 😊\"\n",
    "text = preprocess(text)\n",
    "encoded_input = tokenizer(text, return_tensors='pt')\n",
    "output = model(**encoded_input)\n",
    "scores = output[0][0].detach().numpy()\n",
    "scores = softmax(scores)\n",
    "\n",
    "# # TF\n",
    "# model = TFAutoModelForSequenceClassification.from_pretrained(MODEL)\n",
    "# model.save_pretrained(MODEL)\n",
    "\n",
    "# text = \"Good night 😊\"\n",
    "# encoded_input = tokenizer(text, return_tensors='tf')\n",
    "# output = model(encoded_input)\n",
    "# scores = output[0][0].numpy()\n",
    "# scores = softmax(scores)\n",
    "\n",
    "print(\"tweet-text: \", text)\n",
    "ranking = np.argsort(scores)\n",
    "ranking = ranking[::-1]\n",
    "for i in range(scores.shape[0]):\n",
    "    l = labels[ranking[i]]\n",
    "    s = scores[ranking[i]]\n",
    "    print(f\"{i+1}) {l} {np.round(float(s), 4)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f2m1NjyFwD7W"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
